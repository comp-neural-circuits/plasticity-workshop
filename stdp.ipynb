{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ce8efea6-1a44-4af8-95a8-4276ff8372b1",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d6a7d-8685-4f46-a3ee-7eb1ffcb46c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d0f96-4d16-4df8-abd8-efe13d5a203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib ipywidgets scikit-learn --quiet\n",
    "import numpy as np\n",
    "import scipy.linalg as lin\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "plt.style.use(\"https://github.com/comp-neural-circuits/plasticity-workshop/raw/dev/plots_style.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5a936-6751-4e91-9c8d-d5850358fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySTDP_plot(A_plus, A_minus, tau_plus, tau_minus, Delta_t, dW):\n",
    "  '''\n",
    "  A_plus : maximum amount of potentiation (LTP)\n",
    "  A_minus: maximum amount of depression (LTD)\n",
    "  tau_plus: LTP time constant\n",
    "  tau_minus: LTD time constant \n",
    "  Delta_t : array with the time differences between post- and pre-synaptic spikes\n",
    "  dW : synaptic change \n",
    "  '''\n",
    "  plt.figure()\n",
    "  plt.plot([-5 * tau_minus, 5 * tau_plus], [0, 0], 'k', linestyle=':')\n",
    "  plt.plot([0, 0], [-A_minus, A_plus], 'k', linestyle=':')\n",
    "\n",
    "  plt.plot(Delta_t[Delta_t <= 0], dW[Delta_t <= 0], 'r')\n",
    "  plt.plot(Delta_t[Delta_t > 0], dW[Delta_t > 0], 'b')\n",
    "\n",
    "  plt.xlabel(r'$\\Delta t=$ t$_{\\mathrm{post}}$ - t$_{\\mathrm{pre}}$ (ms)')\n",
    "  plt.ylabel(r'$\\Delta $W', fontsize=14)\n",
    "  plt.title('Pairwise STDP rule', fontsize=12, fontweight='bold')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbfbb6-9f81-44ea-b133-53a2ee134a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Delta_W(A_plus, A_minus, tau_plus, tau_minus, Delta_t):\n",
    "  \"\"\"\n",
    "  Calculates the instantaneous change in weights dW due to the STDP pairwise rule\n",
    "\n",
    "  A_plus : maximum amount of potentiation (LTP)\n",
    "  A_minus: maximum amount of depression (LTD)\n",
    "  tau_plus: LTP time constant\n",
    "  tau_minus: LTD time constant \n",
    "  Delta_t : array with the time differences between post- and pre-synaptic spikes\n",
    "  \"\"\"\n",
    "\n",
    "  # Initialize the STDP change\n",
    "  dW = np.zeros(len(Delta_t))\n",
    "  # Calculate dW for LTP\n",
    "  dW[Delta_t > 0] = A_plus * np.exp(-Delta_t[Delta_t > 0] / tau_plus)\n",
    "  # Calculate dW for LTD\n",
    "  dW[Delta_t <= 0] = -A_minus * np.exp(delta_t[Delta_t <= 0] / tau_minus)\n",
    "\n",
    "  return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193bce4-ba18-42ea-9967-6386c3326299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the STDP rule parameters\n",
    "A_plus = 1\n",
    "A_minus = 1\n",
    "tau_plus = 20  #[ms]\n",
    "tau_minus = 10 #[ms]\n",
    "\n",
    "Delta_t = np.linspace(-5 * tau_minus, 5 * tau_plus, 50)\n",
    "\n",
    "dW = Delta_W(A_plus, A_minus, tau_plus, tau_minus, Delta_t)\n",
    "\n",
    "mySTDP_plot(A_plus, A_minus, tau_plus, tau_minus, Delta_t, dW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/comp-neural-circuits/plasticity-workshop/blob/dev/rate_based.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "70cb080a-e9a3-4007-b9cb-f7ab20b92c2c",
    "deepnote_cell_type": "text-cell-h1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Rate-based Plasticity Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6f485884-d360-4f23-9481-8c834974a155",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Hebbian Plasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9faf8d82-d8b7-41e5-a255-290fb1557024",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Goals**\n",
    "+ Covariance-based learning rule is equivalent to detecting the first principal component of the activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c9f07e91-b33e-49da-9b42-eb3a744cded3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4a92bc37-cb67-4f91-aea7-3682fdd62113",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8501,
    "execution_start": 1644223398431,
    "is_code_hidden": true,
    "is_output_hidden": true,
    "source_hash": "7c291202",
    "tags": [
     "hide_output",
     "remove_output",
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib ipywidgets scikit-learn --quiet\n",
    "import numpy as np\n",
    "import scipy.linalg as lin\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "#plt.style.use(\"https://github.com/comp-neural-circuits/plasticity-workshop/raw/dev/plots_style.txt\")\n",
    "plt.style.use(\"plots_style.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e047227c-e297-436b-aa18-f26e2976f0df",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "94b14042-aade-4b82-8b77-2f6e3d9b3b8e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1644222477799,
    "source_hash": "4199937f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ornstein_uhlenbeck(mean,cov,dt,Ttot,dts=1E-2):\n",
    "  \"\"\"\n",
    "  Generates a multi-dimensional Ornstein-Uhlenbeck process.\n",
    "\n",
    "  Parameters :\n",
    "  mean (numpy vector) : desired mean\n",
    "  cov  (matrix)   : covariance matrix (symmetric, positive definite)\n",
    "  dt   (real)     : timestep output\n",
    "  Tot  (real)     : total time\n",
    "  dts = 1E-3 (real) : simulation timestep\n",
    "\n",
    "  Returns :\n",
    "  times (numpy vector)\n",
    "  rates (numpy matrix)  :  rates[i,j] is the rate of unit i at time times[j]\n",
    "  \"\"\"\n",
    "  times = np.arange(0.0,Ttot,dt)\n",
    "  n = len(mean)\n",
    "  nTs = int(Ttot/dts)\n",
    "  rates_all = np.empty((n,nTs))\n",
    "  rates_all[:,0] = mean\n",
    "  L = lin.cholesky(cov)\n",
    "  nskip = int(dt/dts)\n",
    "  assert round(dts*nskip,5) == dt , \"dt must be multiple of  \" + str(dts)\n",
    "  for t in range(1,nTs):\n",
    "    dr = dts*(mean-rates_all[:,t-1])\n",
    "    dpsi = np.sqrt(2*dts)*(L.T @ rng.standard_normal(n))\n",
    "    rates_all[:,t] = rates_all[:,t-1] + dr + dpsi\n",
    "  # subsample \n",
    "  rates = rates_all[:,::nskip]\n",
    "  return times,rates\n",
    "  \n",
    "def twodimensional_OU(mean1,var1,mean2,var2,corr,dt,Ttot,dts=1E-2):\n",
    "    \"\"\"\n",
    "    Generates samples from a 2D Ornstein-Uhlenbeck process.\n",
    "\n",
    "    Parameters :\n",
    "    mean1 (real) : mean on first dimension\n",
    "    var1  (real) : variance on first dimension (at dt=1. intervals)\n",
    "    mean2 (real) : - \n",
    "    var2  (real) : - \n",
    "    corr  (real) : correlation coefficient \n",
    "    dt   (real)     : timestep output\n",
    "    Tot  (real)     : total time\n",
    "    dts = 1E-3 (real) : simulation timestep\n",
    "\n",
    "    Returns :\n",
    "    times  (numpy vector)\n",
    "    rates1 (numpy vector)\n",
    "    rates2 (numpy vector)\n",
    "    \"\"\"\n",
    "    assert -1<=corr<=1, \"correlation must be in (-1,1) interval\"\n",
    "    var12 = corr*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    (times, rates) = ornstein_uhlenbeck(\n",
    "      np.array([mean1,mean2]),\n",
    "      cov_mat,\n",
    "      dt,Ttot,dts)\n",
    "    return times, rates[0,:],rates[1,:]\n",
    "\n",
    "\n",
    "def plot_r1_and_r2(correlation=0.0,mean_r1=0.0,mean_r2=0.0,var_r1=1.0,var_r2=1.0):\n",
    "    times,rates1,rates2 = twodimensional_OU(mean_r1,var_r1,mean_r2,var_r2,correlation,0.1,60.0)\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8,10)) #gridspec_kw={'height_ratios': [3, 1]})\n",
    "    ax1.plot(times,rates1)\n",
    "    ax1.plot(times,rates2)\n",
    "    ax1.set_xlabel(\"time (s)\")\n",
    "    ax1.set_ylabel(\"rate (Hz)\")\n",
    "    ax1.set_title(\"time traces\")\n",
    "    ax2.scatter(rates1,rates2,color=\"black\")\n",
    "    ax2.set_title(\"samples r1 Vs r2\")\n",
    "    ax2.set_xlabel(\"rate 1 (Hz)\")\n",
    "    ax2.set_ylabel(\"rate 2 (Hz)\")\n",
    "    ax2.axis(\"equal\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize noisy rate inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we generate a noisy rate trace from $N$ neurons. $r_j(t)$ indicates the rate of neuron $j=1,2,\\ldots\\,N$ at time $t$. Neurons are, in general, correlated with each other.\n",
    "\n",
    "In the figure below, you can see the traces of 2 neurons, simulated for 60 seconds. You don't need to read or understand this code. Try to modify some of the parameters to understand their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_r1_and_r2,correlation=(-0.99,0.99,0.01) , mean_r1=(0.0,5.0,0.1),mean_r2=(0.0,5.0,0.1),\n",
    "        var_r1=(0.01,2.0,0.01), var_r2=(0.01,2.0,0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have extra time, check the documentation of the functions `ornstein_uhlenbeck(...)` and `twodimensional_OU(...)`, which are used to generate these traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute response of output neuron based on input activity and weights  (exercise 1 ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r_\\text{out}(t) = \\sum_{j=1}^N w_j r_j(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_response(r_input,weights):\n",
    "    \"\"\"\n",
    "    Computes the response of a neuron that receives a series of inputs over time.  \n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) :  r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights (vector) :  weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    \n",
    "    Returns :\n",
    "    r_output (vector) : r_output[t] is the rate of the output neuron at timestep t\n",
    "    \"\"\"\n",
    "    \n",
    "    # I think this can be done with np.dot , but I don't like to see it applied to matrices\n",
    "    # so I propose a more canonical broadcasting\n",
    "    \n",
    "    r_input_weighted = r_input * weights[:,np.newaxis] # multiply columnwise\n",
    "    r_output = r_input_weighted.sum(axis=0) # and sum columnwise\n",
    "    r_output[r_output < 0 ] = 0  # avoid negative rates\n",
    "    return r_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weight update for correlation based and covariance based rule\n",
    "\n",
    "Now that you have the reponse of the output neuron  $r_\\text{out}(t)$ , you can calculate the update in synaptic weights due to rate-based plasticiy.\n",
    "\n",
    "#### Some notation\n",
    "We use $\\left< \\; \\ldots \\; \\right>_t$ to indicate an average over time. For mean rates, we further simplify the notation, taking the form $ \\bar{r}_j$. Therefore:\n",
    "$$\n",
    "\\bar{r}_j = \\left< r_j(t) \\right>_t = \n",
    "\\frac1T \\int_0^T r_j(t) \\;\\mathrm d t = \n",
    "\\frac{1}{N_T} \\sum_k  r_j(t_k)\n",
    "$$\n",
    "The last equality represents the fact that $r(t)$ is discretized in our code, and $N_T$ indicates the number of discretized steps.\n",
    "\n",
    "\n",
    "#### Correlation-based rule\n",
    "The correlation-based rule is defined as :\n",
    "$$ \n",
    "\\Delta w_j = \\gamma \\; \\left<  r_\\text{out}(t) \\; r_j(t)  \\right>_t\n",
    "$$\n",
    "\n",
    "The second moment can be computed numerically simply as the mean of the element-wise product between the two time series.\n",
    "$$\n",
    "\\left<  r_\\text{out}(t) \\; r_j(t)  \\right>_t = \\frac{1}{N_T}\\sum_k  r_\\text{out}(t_k) \\; r_j(t_k) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_updates_correlation(r_input,weights,gamma):\n",
    "    \"\"\"\n",
    "    Computes the weight updates according to the correlation rule\n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) : r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights (vector) : weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    gamma   (number) : plasticity parameter\n",
    "    T       (number) : total simulation time, in seconds\n",
    "    \n",
    "    Returns :\n",
    "    weight_updates (vector) : the update on each weight after this training interval\n",
    "    \"\"\"\n",
    "\n",
    "    # TIPS : \n",
    "    # use the rate_response function that you defined before !\n",
    "   \n",
    "    r_output = rate_response(r_input,weights)\n",
    "    r_product  = r_output * r_input  # broadcast by row\n",
    "    weight_updates = gamma * r_product.mean(axis=1) # average over time dimension\n",
    "    return weight_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance based rule\n",
    "In the covariance-based rule, we are using a covariance, instead :\n",
    "$$ \n",
    "\\Delta w_j = \\gamma \\; \\left<  \\left(r_\\text{out}(t) - \\bar{r}_\\text{out}\\right)\n",
    "\\; \\left(r_j(t) - \\bar{r}_j \\right)  \\right>_t \\quad \\text{with} \\quad \n",
    "\\bar{r}_\\text{out} = \\left< r_\\text{out}(t) \\right>_t \\quad \\text{and} \\quad\n",
    "\\bar{r}_j = \\left< r_j(t) \\right>_t \n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "*Technical note:*  \n",
    "the weight update rate should really be $\\gamma=\\hat{\\gamma}\\;T$, where $\\hat{\\gamma}$ is the weight update *per second*.  \n",
    "Consider also dimensional analysis: if $\\text{rate}\\sim \\text{time}^{-1}$, then it must be $\\gamma \\sim \\text{time}\\times \\text{weight}$.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_updates_covariance(r_input,weights_current,gamma):\n",
    "    \"\"\"\n",
    "    Computes the weight updates according to the covariance rule\n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) :  r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights_current (vector) :  weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    \n",
    "    Returns :\n",
    "    weight_updates (vector) : the update on each weight after this training interval\n",
    "    \"\"\"\n",
    "    \n",
    "    # TIPS : \n",
    "    # it is very similar to the correlation rule, except you need to subtract the mean rates!\n",
    "    # r_input_means = r_input.mean(axis=1)  # (mean over time axis)\n",
    "    r_output_mean = r_output.mean() # mean of a vector -> scalar value\n",
    "    r_output = rate_response(r_input,weights_current)\n",
    "    r_output_meanzero = r_output - r_output_mean\n",
    "    r_input_means = r_input.mean(axis=1) # mean over time axis\n",
    "    r_input_meanzero = r_input - r_input_means[:,np.newaxis] # broadcast on columns\n",
    "    \n",
    "    # now same as before\n",
    "    r_product = r_output_meanzero * r_input_meanzero\n",
    "    weight_updates = gamma * r_product.mean(axis=1) # mean over time dimension\n",
    "    return weights_update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_evolution_covariance(mean_r1,var1,mean_r2,var2,correlation,\n",
    "                                Tstep=10.0,Nsteps=200,gammahat=1E-3):\n",
    "    weight_ret = np.empty(Nsteps)\n",
    "    times_ret = np.arange(0.0,Tstep*Nsteps,Tstep)\n",
    "    gamma = gammahat*Tstep\n",
    "    weights_start = rng.random(2) * 1E-4\n",
    "    weights_temp = np.copy(weights_start)\n",
    "    for k in range(Nsteps):\n",
    "        weight_ret[k]=weights_temp[0]\n",
    "        times,rates1,rates2 = twodimensional_OU(mean_r1,var1,mean_r2,var2,correlation,1.0,Tstep)\n",
    "        rates_input = np.array([rates1,rates2])\n",
    "        weight_updates = weight_updates_correlation(rates_input,weights_temp,gamma)\n",
    "        weights_temp += weight_updates\n",
    "    \n",
    "    # analytic solution\n",
    "    weight_ret_sol = np.empty(Nsteps)\n",
    "    var12 = correlation*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    r_means = np.array([mean_r1,mean_r2])\n",
    "    weights_temp = np.copy(weights_start)\n",
    "    M = gamma*(cov_mat + np.outer(r_means,r_means))\n",
    "    for (k,tk) in enumerate(times_ret):\n",
    "        #weights_temp = lin.expm(M*tk) @ weights_start\n",
    "        weights_temp = np.linalg.matrix_power(M+np.identity(2),k) @ weights_start\n",
    "        weight_ret_sol[k] = weights_temp[0]\n",
    "        \n",
    "    return times_ret,weight_ret,weight_ret_sol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times,w1out,w1sout = weight_evolution_covariance(1.0,0.2,3.,0.1,0.8)\n",
    "plt.plot(times,w1out,times,w1sout)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[rng.random(3),np.zeros(3)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "5e3b54db-e48f-43a7-b40f-09467f2d2c99",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

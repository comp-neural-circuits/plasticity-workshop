{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/comp-neural-circuits/plasticity-workshop/blob/dev/rate_based.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "70cb080a-e9a3-4007-b9cb-f7ab20b92c2c",
    "deepnote_cell_type": "text-cell-h1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Rate-based Plasticity Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6f485884-d360-4f23-9481-8c834974a155",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Hebbian Plasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9faf8d82-d8b7-41e5-a255-290fb1557024",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Goals**\n",
    "+ Covariance-based learning rule is equivalent to detecting the first principal component of the activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c9f07e91-b33e-49da-9b42-eb3a744cded3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "4a92bc37-cb67-4f91-aea7-3682fdd62113",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8501,
    "execution_start": 1644223398431,
    "is_code_hidden": true,
    "is_output_hidden": true,
    "source_hash": "7c291202",
    "tags": [
     "hide_output",
     "remove_output",
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib ipywidgets scikit-learn panel --quiet\n",
    "import numpy as np\n",
    "import scipy.linalg as lin\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# for the PCA\n",
    "from sklearn.decomposition import PCA\n",
    "plt.style.use(\"https://github.com/comp-neural-circuits/plasticity-workshop/raw/dev/plots_style.txt\")#\n",
    "#plt.style.use(\"plots_style.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e047227c-e297-436b-aa18-f26e2976f0df",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "94b14042-aade-4b82-8b77-2f6e3d9b3b8e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1644222477799,
    "source_hash": "4199937f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ornstein_uhlenbeck(mean,cov,dt,Ttot,dts=1E-2):\n",
    "    \"\"\"\n",
    "    Generates a multi-dimensional Ornstein-Uhlenbeck process.\n",
    "\n",
    "    Parameters :\n",
    "    mean (numpy vector) : desired mean\n",
    "    cov  (matrix)   : covariance matrix (symmetric, positive definite)\n",
    "    dt   (real)     : timestep output\n",
    "    Tot  (real)     : total time\n",
    "    dts = 1E-3 (real) : simulation timestep\n",
    "\n",
    "    Returns :\n",
    "    times (numpy vector)\n",
    "    rates (numpy matrix)  :  rates[i,j] is the rate of unit i at time times[j]\n",
    "    \"\"\"\n",
    "    times = np.arange(0.0,Ttot,dt)\n",
    "    n = len(mean)\n",
    "    nTs = int(Ttot/dts)\n",
    "    rates_all = np.empty((n,nTs))\n",
    "    rates_all[:,0] = mean\n",
    "    L = lin.cholesky(cov)\n",
    "    nskip = int(dt/dts)\n",
    "    assert round(dts*nskip,5) == dt , \"dt must be multiple of  \" + str(dts)\n",
    "    for t in range(1,nTs):\n",
    "        dr = dts*(mean-rates_all[:,t-1])\n",
    "        dpsi = np.sqrt(2*dts)*(L.T @ rng.standard_normal(n))\n",
    "        rates_all[:,t] = rates_all[:,t-1] + dr + dpsi\n",
    "    # subsample \n",
    "    rates = rates_all[:,::nskip]\n",
    "    return times,rates\n",
    "  \n",
    "def twodimensional_OU(mean1,var1,mean2,var2,corr,dt,Ttot,dts=1E-2):\n",
    "    \"\"\"\n",
    "    Generates samples from a 2D Ornstein-Uhlenbeck process.\n",
    "\n",
    "    Parameters :\n",
    "    mean1 (real) : mean on first dimension\n",
    "    var1  (real) : variance on first dimension (at dt=1. intervals)\n",
    "    mean2 (real) : - \n",
    "    var2  (real) : - \n",
    "    corr  (real) : correlation coefficient \n",
    "    dt   (real)     : timestep output\n",
    "    Tot  (real)     : total time\n",
    "    dts = 1E-3 (real) : simulation timestep\n",
    "\n",
    "    Returns :\n",
    "    times  (numpy vector)\n",
    "    rates1 (numpy vector)\n",
    "    rates2 (numpy vector)\n",
    "    \"\"\"\n",
    "    assert -1<corr<1, \"correlation must be in (-1,1) interval\"\n",
    "    var12 = corr*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    (times, rates) = ornstein_uhlenbeck(\n",
    "      np.array([mean1,mean2]),\n",
    "      cov_mat,\n",
    "      dt,Ttot,dts)\n",
    "    return times, rates #rates[0,:],rates[1,:]\n",
    "\n",
    "\n",
    "def plot_r1_and_r2(correlation=0.0,mean_r1=0.0,mean_r2=0.0,var_r1=1.0,var_r2=1.0):\n",
    "    times,rates = twodimensional_OU(mean_r1,var_r1,mean_r2,var_r2,correlation,0.1,60.0)\n",
    "    rates1 = rates[0,:]\n",
    "    rates2 = rates[1,:]\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8,10)) #gridspec_kw={'height_ratios': [3, 1]})\n",
    "    ax1.plot(times,rates1)\n",
    "    ax1.plot(times,rates2)\n",
    "    ax1.set_xlabel(\"time (s)\")\n",
    "    ax1.set_ylabel(\"rate (Hz)\")\n",
    "    ax1.set_title(\"time traces\")\n",
    "    ax2.scatter(rates1,rates2,color=\"black\")\n",
    "    ax2.set_title(\"samples r1 Vs r2\")\n",
    "    ax2.set_xlabel(\"rate 1 (Hz)\")\n",
    "    ax2.set_ylabel(\"rate 2 (Hz)\")\n",
    "    ax2.axis(\"equal\")\n",
    "    return \n",
    "\n",
    "def analytic_correlation_based(r_means,r_cov,times,weights_start,gamma):\n",
    "    \"\"\"\n",
    "    Computes the analytic solution for the correlation-based\n",
    "    plasticity rule. Assuming the input is a multi dimensional \n",
    "    O-U process.\n",
    "    \n",
    "    Parameters :\n",
    "    r_means (vector) : input means\n",
    "    r_cov   (matrix) : input covariance matrix\n",
    "    times   (vector) : time vector\n",
    "    weights_start (vector) : initial conditions for weights\n",
    "    gamma   (number) : learning coefficient\n",
    "    \n",
    "    Returns :\n",
    "    weights (matrix) : weights[i,k] is the weight from neuron i at time times[k]\n",
    "    \"\"\"\n",
    "    Ntimes = len(times)\n",
    "    N = len(r_means)\n",
    "    weights = np.empty((N,Ntimes))\n",
    "    M = gamma*(r_cov + np.outer(r_means,r_means)) + np.identity(N)\n",
    "    for k in range(Ntimes):\n",
    "        weights[:,k] = np.linalg.matrix_power(M,k) @ weights_start\n",
    "    return weights\n",
    "\n",
    "def analytic_covariance_based(r_means,r_cov,times,weights_start,gamma):\n",
    "    \"\"\"\n",
    "    Computes the analytic solution for the covariance-based\n",
    "    plasticity rule. Assuming the input is a multi dimensional \n",
    "    O-U process.\n",
    "    \n",
    "    Parameters :\n",
    "    r_means (vector) : input means\n",
    "    r_cov   (matrix) : input covariance matrix\n",
    "    times   (vector) : time vector\n",
    "    weights_start (vector) : initial conditions for weights\n",
    "    gamma   (number) : learning coefficient \n",
    "    \n",
    "    Returns :\n",
    "    weights (matrix) : weights[i,k] is the weight from neuron i at time times[k]\n",
    "    \"\"\"\n",
    "    Ntimes = len(times)\n",
    "    N = len(r_means)\n",
    "    weights = np.empty((N,Ntimes))\n",
    "    M = gamma*r_cov + np.identity(N)\n",
    "    for k in range(Ntimes):\n",
    "        weights[:,k] = np.linalg.matrix_power(M,k) @ weights_start\n",
    "    return weights\n",
    "\n",
    "\n",
    "\n",
    "def test_weight_update_correlation():\n",
    "    # numeric result\n",
    "    mean_r1,var1 = 3.0,0.3\n",
    "    mean_r2,var2 = 5.0, 0.2\n",
    "    correlation = 0.7\n",
    "    T = 100.0\n",
    "    gamma = 1.0\n",
    "    weights = rng.random(2) + 5.0\n",
    "    times,rates_input = twodimensional_OU(mean_r1,var1,mean_r2,var2,correlation,0.2,T)\n",
    "    weight_update = weight_update_correlation(rates_input,weights,gamma)\n",
    "    \n",
    "    # analytic result\n",
    "    var12 = correlation*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    r_means = np.array([mean_r1,mean_r2])\n",
    "    weights_an = analytic_correlation_based(r_means,cov_mat,np.array([0,T]),weights,gamma)[:,1]\n",
    "    weight_update_an = weights_an - weights\n",
    "    print(f\"expected (approx): {weight_update_an} \\t function output {weight_update}\") \n",
    "    if all(np.isclose(weight_update,weight_update_an,rtol=0.3)):\n",
    "        print(\"**** test PASSED ! ****\")\n",
    "    else:\n",
    "        print(\"**** test FAILED ! ****\")\n",
    "    return\n",
    " \n",
    "def test_weight_update_covariance():\n",
    "    # numeric result\n",
    "    mean_r1,var1 = 3.0,0.3\n",
    "    mean_r2,var2 = 5.0, 0.2\n",
    "    correlation = 0.7\n",
    "    T = 100.0\n",
    "    gamma = 1.0\n",
    "    weights = rng.random(2) + 5.0\n",
    "    times,rates_input = twodimensional_OU(mean_r1,var1,mean_r2,var2,correlation,0.2,T)\n",
    "    weight_update = weight_update_covariance(rates_input,weights,gamma)\n",
    "    \n",
    "    # analytic result\n",
    "    var12 = correlation*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    r_means = np.array([mean_r1,mean_r2])\n",
    "    weights_an = analytic_covariance_based(r_means,cov_mat,np.array([0,T]),weights,gamma)[:,1]\n",
    "    weight_update_an = weights_an - weights\n",
    "    print(f\"expected (approx): {weight_update_an} \\t function output {weight_update}\") \n",
    "    if all(np.isclose(weight_update,weight_update_an,rtol=0.3)):\n",
    "        print(\"**** test PASSED ! ****\")\n",
    "    else:\n",
    "        print(\"**** test FAILED ! ****\")\n",
    "\n",
    "        \n",
    "def weight_evolution_correlation(mean_r1,var1,mean_r2,var2,correlation,\n",
    "                                 weights_start,Tstep=100.0,Nsteps=20,gammahat=1E-3,dtsample=0.2):\n",
    "    weight_ret = np.empty(Nsteps)\n",
    "    times_ret = np.arange(0.0,Tstep*Nsteps,Tstep)\n",
    "    gamma = gammahat*Tstep\n",
    "    weights_temp = np.copy(weights_start)\n",
    "    for k in range(Nsteps):\n",
    "        weight_ret[k]=weights_temp[0]\n",
    "        _times,_rates_input = twodimensional_OU(mean_r1,var1,mean_r2,var2,correlation,dtsample,Tstep)\n",
    "        _weight_updates = weight_update_correlation(_rates_input,weights_temp,gamma)\n",
    "        weights_temp += _weight_updates\n",
    "    \n",
    "    # analytic solution\n",
    "    var12 = correlation*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    r_means = np.array([mean_r1,mean_r2])\n",
    "    weights_an = analytic_correlation_based(r_means,cov_mat,times_ret,weights_start,gamma)\n",
    "        \n",
    "    return times_ret,weight_ret,weights_an[0,:]\n",
    "\n",
    "def weight_evolution_covariance(mean_r1,var1,mean_r2,var2,correlation,\n",
    "                                weights_start,Tstep=100.0,Nsteps=20,gammahat=1E-3,dtsample=0.2):\n",
    "    weight_ret = np.empty(Nsteps)\n",
    "    times_ret = np.arange(0.0,Tstep*Nsteps,Tstep)\n",
    "    gamma = gammahat*Tstep\n",
    "    weights_temp = np.copy(weights_start)\n",
    "    for k in range(Nsteps):\n",
    "        weight_ret[k]=weights_temp[0]\n",
    "        _times,_rates_input = twodimensional_OU(mean_r1,var1,mean_r2,var2,correlation,dtsample,Tstep)\n",
    "        weight_updates = weight_update_covariance(_rates_input,weights_temp,gamma)\n",
    "        weights_temp += weight_updates\n",
    "    \n",
    "    # analytic solution\n",
    "    var12 = correlation*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    r_means = np.array([mean_r1,mean_r2])\n",
    "    weights_an = analytic_covariance_based(r_means,cov_mat,times_ret,weights_start,gamma)\n",
    "        \n",
    "    return times_ret,weight_ret,weights_an[0,:]\n",
    "\n",
    "def weight_evo_all(mean_r1,var1,mean_r2,var2,correlation,):\n",
    "    weights_start = np.array([1E-2,1E-2])\n",
    "    times,wcorr,wcorran = weight_evolution_correlation(mean_r1,var1,mean_r2,\\\n",
    "                                                       var2,correlation,weights_start)\n",
    "    _,wcov,wcovan = weight_evolution_covariance(mean_r1,var1,mean_r2,\\\n",
    "                                                       var2,correlation,weights_start)\n",
    "    times += times[1]-times[0] # time starts from value >0 , so I can plot in log-log scale\n",
    "    fig,ax = plt.subplots()\n",
    "    linecorr, = ax.plot(times,wcorr,color=\"xkcd:ocean blue\",label=\"correlation-based\")\n",
    "    # plt.plot(times,wcorran,'--',color=\"xkcd:ocean blue\",alpha=0.8)\n",
    "    \n",
    "    linecov, = ax.plot(times,wcov,color=\"xkcd:blood red\",label=\"covariance-based\")\n",
    "    # plt.plot(times,wcovan,'--',color=\"xkcd:blood red\",alpha=0.8)\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('time (s)')\n",
    "    ax.set_ylabel('synaptic weight')\n",
    "    ax.legend(handles=[linecorr,linecov])\n",
    "    return \n",
    "\n",
    "#### PCA PART ###\n",
    "\n",
    "def first_principal_component(x):\n",
    "    \"\"\"\n",
    "    Computes the first principal component from x\n",
    "    \n",
    "    Parameters:\n",
    "    x (matrix) :  x[k,i] is the value of the i component of x at time t[k]\n",
    "    \n",
    "    Returns :\n",
    "    pca1 (vector) : vector of norm 1 that captures the direction of maximum variability\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(x)\n",
    "    return pca.components_[0,:]\n",
    "\n",
    "\n",
    "def plot_r1_and_r2_with_PCA(mean_r1=0.0,mean_r2=0.0,var_r1=1.0,var_r2=1.0,correlation=0.6,):\n",
    "    times,rates_input = twodimensional_OU(mean_r1,var_r1,mean_r2,var_r2,correlation,0.1,60.0)\n",
    "    rates1 = rates_input[0,:]\n",
    "    rates2 = rates_input[1,:]\n",
    "    pcavec = first_principal_component(rates_input.T)\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8,10)) #gridspec_kw={'height_ratios': [3, 1]})\n",
    "    ax1.plot(times,rates1)\n",
    "    ax1.plot(times,rates2)\n",
    "    ax1.set_xlabel(\"time (s)\")\n",
    "    ax1.set_ylabel(\"rate (Hz)\")\n",
    "    ax1.set_title(\"time traces\")\n",
    "    \n",
    "    ax2.scatter(rates1,rates2,color=\"black\")\n",
    "    ax2.set_title(\"samples r1 Vs r2\")\n",
    "    ax2.set_xlabel(\"rate 1 (Hz)\")\n",
    "    ax2.set_ylabel(\"rate 2 (Hz)\")\n",
    "    ax2.axis(\"equal\")\n",
    "    xmin,xmax = ax2.get_xlim()\n",
    "    ymin,ymax = ax2.get_ylim()\n",
    "    xpca_plot = np.array([-pcavec[0]*100,pcavec[0]*100])+mean_r1\n",
    "    ypca_plot = np.array([-pcavec[1]*100,pcavec[1]*100])+mean_r2\n",
    "    ax2.plot(xpca_plot,ypca_plot,\"--\",color=\"red\")\n",
    "    ax2.set_xlim((xmin,xmax))\n",
    "    ax2.set_ylim((ymin,ymax))\n",
    "    return\n",
    "\n",
    "def plot_covrule_and_PCA(mean_r1=0.0,mean_r2=0.0,var_r1=1.0,var_r2=1.0,correlation=0.6):\n",
    "    gammahat=1E-3\n",
    "    Tstep=100.\n",
    "    Nsteps=20\n",
    "    dtsample=1.0\n",
    "    times,rates_input = twodimensional_OU(mean_r1,var_r1,mean_r2,var_r2,correlation,0.2,100.0)\n",
    "    pcavec = first_principal_component(rates_input.T)\n",
    "    \n",
    "    # now, covariance rule\n",
    "    weights_start = np.array([1E-1,1E-1])\n",
    "    gamma = gammahat*Tstep\n",
    "    weights_end = np.copy(weights_start)\n",
    "    for k in range(Nsteps):\n",
    "        _times,_rates_input = twodimensional_OU(mean_r1,var_r1,mean_r2,var_r2,correlation,dtsample,Tstep)\n",
    "        _weight_updates = weight_update_covariance(_rates_input,weights_end,gamma)\n",
    "        weights_end += _weight_updates\n",
    "    \n",
    "    fig,ax= plt.subplots()\n",
    "    weights_end = weights_end / lin.norm(weights_end) \n",
    "    \n",
    "    \n",
    "    ax.scatter(rates1,rates2,color=\"black\")\n",
    "    ax.set_xlabel(\"rate 1 (Hz)\")\n",
    "    ax.set_ylabel(\"rate 2 (Hz)\")\n",
    "    ax.axis(\"equal\")\n",
    "    xmin,xmax = ax.get_xlim()\n",
    "    ymin,ymax = ax.get_ylim()\n",
    "    xpca_plot = np.array([-pcavec[0]*100,pcavec[0]*100])+mean_r1\n",
    "    ypca_plot = np.array([-pcavec[1]*100,pcavec[1]*100])+mean_r2\n",
    "    linepca,=ax.plot(xpca_plot,ypca_plot,\"--\",color=\"red\",label=\"1st principal component \")\n",
    "    \n",
    "    xw_plot = np.array([-weights_end[0]*100,weights_end[0]*100])+mean_r1\n",
    "    yw_plot = np.array([-weights_end[1]*100,weights_end[1]*100])+mean_r2\n",
    "    lineweights,=ax.plot(xw_plot,yw_plot,\"--\",color=\"blue\",label=\"weights after learning\")\n",
    "    \n",
    "    ax.set_xlim((xmin,xmax))\n",
    "    ax.set_ylim((ymin,ymax))\n",
    "    \n",
    "    ax.legend(handles=[linepca,lineweights])\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize noisy rate inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we generate a noisy rate trace from $N$ neurons. $r_j(t)$ indicates the rate of neuron $j=1,2,\\ldots\\,N$ at time $t$. Neurons are, in general, correlated with each other.\n",
    "\n",
    "In the figure below, you can see the traces of 2 neurons, simulated for 60 seconds. You don't need to read or understand this code. Try to modify some of the parameters to understand their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b02b08c4d649afb42015eda3d96434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='correlation', max=0.99, min=-0.99, step=0.01), Float…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_r1_and_r2,correlation=(-0.99,0.99,0.01) , mean_r1=(0.0,5.0,0.1),mean_r2=(0.0,5.0,0.1),\n",
    "        var_r1=(0.01,2.0,0.01), var_r2=(0.01,2.0,0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have extra time, check the documentation of the functions `ornstein_uhlenbeck(...)` and `twodimensional_OU(...)`, which are used to generate these traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 . Compute response of output neuron based on input activity and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r_\\text{out}(t) = \\sum_{j=1}^N w_j r_j(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "def rate_response(r_input,weights):\n",
    "    \"\"\"\n",
    "    Computes the response of a neuron that receives a series of inputs over time.  \n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) :  r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights (vector) :  weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    \n",
    "    Returns :\n",
    "    r_output (vector) : r_output[t] is the rate of the output neuron at timestep t\n",
    "    \"\"\"\n",
    "    \n",
    "    # I think this can be done with np.dot , but I don't like to see it applied to matrices\n",
    "    # so I propose a more canonical broadcasting\n",
    "    \n",
    "    r_input_weighted = r_input * weights[:,np.newaxis] # multiply columnwise\n",
    "    r_output = r_input_weighted.sum(axis=0) # and sum columnwise\n",
    "    # r_output[r_output < 0 ] = 0  # avoid negative rates\n",
    "    return r_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weight update for correlation based and covariance based rule\n",
    "\n",
    "Now that you have the reponse of the output neuron  $r_\\text{out}(t)$ , you can calculate the update in synaptic weights due to rate-based plasticiy.\n",
    "\n",
    "#### Some notation\n",
    "We use $\\left< \\; \\ldots \\; \\right>_t$ to indicate an average over time. For mean rates, we further simplify the notation, taking the form $ \\bar{r}_j$. Therefore:\n",
    "$$\n",
    "\\bar{r}_j = \\left< r_j(t) \\right>_t = \n",
    "\\frac1T \\int_0^T r_j(t) \\;\\mathrm d t = \n",
    "\\frac{1}{N_T} \\sum_k  r_j(t_k)\n",
    "$$\n",
    "The last equality represents the fact that $r(t)$ is discretized in our code, and $N_T$ indicates the number of discretized steps.\n",
    "\n",
    "\n",
    "#### Correlation-based rule\n",
    "The correlation-based rule is defined as :\n",
    "$$ \n",
    "\\Delta w_j = \\gamma \\; \\left<  r_\\text{out}(t) \\; r_j(t)  \\right>_t\n",
    "$$\n",
    "\n",
    "The second moment can be computed numerically simply as the mean of the element-wise product between the two time series.\n",
    "$$\n",
    "\\left<  r_\\text{out}(t) \\; r_j(t)  \\right>_t = \\frac{1}{N_T}\\sum_k  r_\\text{out}(t_k) \\; r_j(t_k) \n",
    "$$\n",
    "\n",
    "\n",
    "----\n",
    "*Technical note:*  \n",
    "the weight update rate should really be $\\gamma=\\hat{\\gamma}\\;T$, where $\\hat{\\gamma}$ is the weight update *per second*.  \n",
    "Consider also dimensional analysis: if $\\text{rate}\\sim \\text{time}^{-1}$, then it must be $\\gamma \\sim \\text{time}\\times \\text{weight}$.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "def weight_update_correlation(r_input,weights,gamma):\n",
    "    \"\"\"\n",
    "    Computes the weight updates according to the correlation rule\n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) : r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights (vector) : weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    gamma   (number) : plasticity parameter\n",
    "    T       (number) : total simulation time, in seconds\n",
    "    \n",
    "    Returns :\n",
    "    weight_updates (vector) : the update on each weight after this training interval\n",
    "    \"\"\"\n",
    "\n",
    "    # TIPS : \n",
    "    # use the rate_response function that you defined before !\n",
    "   \n",
    "    r_output = rate_response(r_input,weights)\n",
    "    r_product  = r_output * r_input  # broadcast by row\n",
    "    weight_updates = gamma * r_product.mean(axis=1) # average over time dimension\n",
    "    return weight_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the exercise\n",
    "\n",
    "To test your function, run the cell below. It should return `test PASSED !` if it errors, or returns `test FAILED !` please review your solution before you proceed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected (approx): [128.20327555 211.52486139] \t function output [117.12653595 200.7566447 ]\n",
      "**** test PASSED ! ****\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "test_weight_update_correlation()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Covariance based rule\n",
    "In the covariance-based rule, we are using a covariance, instead :\n",
    "\n",
    "$$ \n",
    "\\Delta w_j = \\gamma \\; \\left<  \\left(r_\\text{out}(t) - \\bar{r}_\\text{out}\\right)\n",
    "\\; \\left(r_j(t) - \\bar{r}_j \\right)  \\right>_t \\quad \\text{with} \\quad \n",
    "\\bar{r}_\\text{out} = \\left< r_\\text{out}(t) \\right>_t \\quad \\text{and} \\quad\n",
    "\\bar{r}_j = \\left< r_j(t) \\right>_t\n",
    "$$\n",
    "\n",
    "To compute this quantity numerically, simply subtract the means from the rate traces, and then proceed as in the previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "def weight_update_covariance(r_input,weights,gamma):\n",
    "    \"\"\"\n",
    "    Computes the weight updates according to the covariance rule\n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) :  r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights (vector) :  weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    \n",
    "    Returns :\n",
    "    weight_updates (vector) : the update on each weight after this training interval\n",
    "    \"\"\"\n",
    "    \n",
    "    # TIPS : \n",
    "    # it is very similar to the correlation rule, except you need to subtract the mean rates!\n",
    "    # r_input_means = r_input.mean(axis=1)  # (mean over time axis)\n",
    "    r_output = rate_response(r_input,weights)\n",
    "    r_output_mean = r_output.mean() # mean of a vector -> scalar value\n",
    "    r_output_meanzero = r_output - r_output_mean\n",
    "    r_input_means = r_input.mean(axis=1) # mean over time axis\n",
    "    r_input_meanzero = r_input - r_input_means[:,np.newaxis] # broadcast on columns\n",
    "    # now same as before\n",
    "    r_product = r_output_meanzero * r_input_meanzero # elementwise product\n",
    "    weight_updates = gamma * r_product.mean(axis=1) # mean over time\n",
    "    return weight_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the exercise\n",
    "\n",
    "As before, to test your function, run the cell below. It should return `test PASSED !` if it errors, or returns `test FAILED !` please review your solution before you proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected (approx): [2.56642245 2.00995546] \t function output [2.53656016 2.10519688]\n",
      "**** test PASSED ! ****\n"
     ]
    }
   ],
   "source": [
    "# TEST \n",
    "test_weight_update_covariance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize $w(t)$ for covariance vs correlation rule\n",
    "\n",
    "Here we show how how one synaptic weight would change over time, according to the two rules. This system has two input neurons and one output neuron. For simplicity we only show the first weights.\n",
    "\n",
    "The code simulates rate activity for $t=100\\; \\text{s}$, keeping weights stationary, and then updates the weights based on the correlation/covariance computed in that interval. This is repeated several times so that we can observe the change of weight over time.\n",
    "\n",
    "The weight is not stable, and tends to reach very high values, therefore we show it using a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1e8f8537f840a599d2ee55694f2056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.5, description='mean_r1', max=5.0), FloatSlider(value=1.0, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact_manual(weight_evo_all, mean_r1=(0.0,5.0,0.1),var1=(0.01,2.0,0.01),\n",
    "         mean_r2=(0.0,5.0,0.1),var2=(0.01,2.0,0.01) , correlation=(-0.99,0.99,0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Which rule results in a faster growth of the weight, and why ?\n",
    "+ Which factor is determining the higher growth ?\n",
    "+ When do the two rules coincide, and why is that ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The covariance rule corresponds to the first principal component of the input rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider again the time-traces of two input neurons, $r_1(t)$ and $r_2(t)$. This time focus on the second plot: it shows samples of the two activities over time.\n",
    "\n",
    "The **first principal component**, in red, represents the direction where most of the variance lies. \n",
    "\n",
    "Here we use `scikit-learn` to compute it: \n",
    "```python\n",
    "r_input = ... <generate neural activity>\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(r_input)\n",
    "first_component = pca.components_[0,:]\n",
    "```\n",
    "Warning ! For the scikit-learn fit we need the format `r_input[k,i]`, where `k` represents time `t[k]` and `i` is the neuron.\n",
    "\n",
    "Change the parameters and see how the PCA follows the scatter plot accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d5cac6915b484e951304040c35d0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='mean_r1', max=5.0), FloatSlider(value=0.0, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_r1_and_r2_with_PCA,correlation=(-0.99,0.99,0.01) , mean_r1=(0.0,5.0,0.1),mean_r2=(0.0,5.0,0.1),\n",
    "        var_r1=(0.01,2.0,0.01), var_r2=(0.01,2.0,0.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare the direction of the PCA with the normalized weights $(w_1,w_2)$ after learning with the covariance rule. The two lines coincide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa07fc72d1a4f2c9622c7445c66b49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='mean_r1', max=5.0), FloatSlider(value=0.0, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "interact_manual(plot_covrule_and_PCA,correlation=(-0.99,0.99,0.01) , mean_r1=(0.0,5.0,0.1),mean_r2=(0.0,5.0,0.1),\n",
    "        var_r1=(0.01,2.0,0.01), var_r2=(0.01,2.0,0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounded plasticity\n",
    "In this section, we modify the plasticity rule, so that synaptic weights do not diverge to $+\\infty$ exponentially. We denote the covariance matrix of the input rates as $C$. Therefore :\n",
    "$$\n",
    "C_{ij} := \\left<  \\left(r_i(t) - \\bar{r}_i\\right)\n",
    "\\; \\left(r_j(t) - \\bar{r}_j \\right)  \\right>_t\n",
    "$$\n",
    "\n",
    "We consider two types of normalization, defined in vector form:\n",
    "\n",
    "**Subtractive normalization**\n",
    "$$\n",
    "\\Delta \\mathbf w = \\gamma \\; \\left(  C \\, \\mathbf w -\n",
    "\\frac{\\boldsymbol{1}^\\top \\,C \\,\\mathbf{w}}{N} \\boldsymbol{1}  \\right)\n",
    "\\;\\; \\text{where}\\;\\; \\mathbf w = (w_1,w_2,\\ldots w_N)\n",
    "\\;\\; \\text{and}\\;\\; \\boldsymbol{1} = (1,1\\ldots 1)  \\;\\;\\text{$N$ times}\n",
    "$$\n",
    "**Divisive normalization**\n",
    "$$\n",
    "\\Delta \\mathbf w = \\gamma \\; \\left(  C \\, \\mathbf w -\n",
    "\\frac{\\boldsymbol{1}^\\top \\,C \\,\\mathbf{w}}{ \\boldsymbol{1}^\\top \\,\\mathbf{w}}\n",
    "\\mathbf{w}  \\right)\n",
    "\\;\\; \\text{where}\\;\\; \\mathbf w = (w_1,w_2,\\ldots w_N)\n",
    "\\;\\; \\text{and}\\;\\; \\boldsymbol{1} = (1,1\\ldots 1)  \\;\\;\\text{$N$ times}\n",
    "$$\n",
    "\n",
    "The last exercise consists in writing the weight update function for these two new rules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "def weigth_update_bounded_subtractive(cov_mat,weights,gamma):\n",
    "    \"\"\"\n",
    "    Covariance-based weight update with subtractive normalization \n",
    "    \"\"\"\n",
    "    N = len(weights)\n",
    "    onevec = np.ones(N)\n",
    "    cov_times_w = cov_mat @ weights\n",
    "    return gamma * ( cov_times_w - cov_times_w.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "def weigth_update_bounded_divisive(cov_mat,weights,gamma):\n",
    "    \"\"\"\n",
    "    Covariance-based weight update with divisive normalization \n",
    "    \"\"\"\n",
    "    N = len(weights)\n",
    "    onevec = np.ones(N)\n",
    "    cov_times_w = cov_mat @ weights\n",
    "    wsum = weights.sum()\n",
    "    if wsum == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        retpiece = (cov_times_w.sum()/wsum) * weights\n",
    "        retval = gamma * ( cov_times_w - (cov_times_w.sum()/wsum) * weights )\n",
    "        return retval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** TO DO ***** \n",
    "# test the functions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The next exercise is to complete the missing parts in the training function. The algorithm does the following:\n",
    "   1. start with some initial synaptic weights \n",
    "   1. simulate input neural rates for 60 seconds\n",
    "   1. compute the covariance matrix\n",
    "   1. update the weights\n",
    "   1. go back to point 2, until convergence (e.g. a sufficiently long time)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_weights_bounded(mean_r1,var_r1,mean_r2,var_r2,correlation,\n",
    "                          w1_start,w2_start,\n",
    "                          wmin = 0.0, wmax = 1.0,\n",
    "                          do_subtractive=True,\n",
    "                          Tcycle=60.0,Ncycles=100,gammahat=1E-3):\n",
    "    \n",
    "    N = 2\n",
    "    \n",
    "    # select which normalization takes place\n",
    "    # (E) : complete with function names\n",
    "    if do_subtractive:\n",
    "        weight_update_fun = weigth_update_bounded_subtractive\n",
    "    else:\n",
    "        weight_update_fun = weigth_update_bounded_divisive\n",
    "    \n",
    "    # these are the times at which the weights are updated\n",
    "    times_ret = np.arange(0,Tcycle*Ncycles,Tcycle)\n",
    "    \n",
    "    # (E) initialize small weights. Use np.random.rand(...) to generate random values    \n",
    "    weights = np.empty((N,Ncycles))\n",
    "    weights[:,0] = np.array([w1_start,w2_start]) \n",
    "    \n",
    "    # Do several 60 second cycles\n",
    "    gamma = gammahat * Tcycle\n",
    "    for k in range(Ncycles-1):\n",
    "        _time,_rate_inputs = twodimensional_OU(mean_r1,var_r1,mean_r2,var_r2,correlation,1.0,Tcycle)\n",
    "        # (E) compute the covariance matrix of the input rates\n",
    "        # using np.cov\n",
    "        # then update the weights using the functions defined before\n",
    "        _cov_mat = np.cov(_rate_inputs)\n",
    "        wtemp =  weights[:,k] + weight_update_fun(_cov_mat,weights[:,k],gamma)\n",
    "        wtemp[wtemp<wmin] = wmin\n",
    "        wtemp[wtemp>wmax] = wmax\n",
    "        weights[:,k+1] = wtemp\n",
    "    \n",
    "    return times_ret, weights\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "times,weights = train_weights_bounded( 1.,0.5,4.,0.5,0.0,\n",
    "                                      0.4,0.8,\n",
    "                                      do_subtractive=False,\n",
    "                                    Tcycle=60.0,Ncycles=100)\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3649288299828636, 0.414927907167653, 0.7850720928323469, 0.8350711700171366)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(weights[0,:],weights[1,:])\n",
    "ax.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_weights_vector_field_direction(\n",
    "                          var1,var2,correlation,\n",
    "                          weights,gamma,\n",
    "                          wmin = 0.0, wmax = 1.0,\n",
    "                          do_subtractive=True):\n",
    "    \n",
    "    if do_subtractive:\n",
    "        weight_update_fun = weigth_update_bounded_subtractive\n",
    "    else:\n",
    "        weight_update_fun = weigth_update_bounded_divisive\n",
    "    # analytic, for speed\n",
    "    var12 = correlation*np.sqrt(var1*var2)\n",
    "    cov_mat = np.array([[var1,var12],[var12,var2]])\n",
    "    deltaw = weight_update_fun(cov_mat,weights,gamma)\n",
    "    new_weights = weights + deltaw\n",
    "    new_weights[new_weights<wmin] = wmin\n",
    "    new_weights[new_weights>wmax] = wmax\n",
    "    return new_weights - weights\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_weights_bounded_plot(mean_r1=1.0,mean_r2=3.0,var_r1=1.0,var_r2=1.001,correlation=0.0,\n",
    "                          w1_start=0.3,w2_start=0.5,\n",
    "                          do_subtractive=True):\n",
    "    wmin,wmax = 0.0,1.0\n",
    "    Tcycle = 60.0\n",
    "    Ncycles = 200\n",
    "    gammahat=1E-3\n",
    "    times,weights = train_weights_bounded(\n",
    "                          mean_r1,var_r1,mean_r2,var_r2,correlation,\n",
    "                          w1_start,w2_start,\n",
    "                          wmin = wmin, wmax = wmax,\n",
    "                          do_subtractive=do_subtractive,\n",
    "                          Tcycle=Tcycle,Ncycles=Ncycles,gammahat=gammahat)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(10,10))\n",
    "    ax.scatter(weights[0,:],weights[1,:])\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_xlim((wmin-0.05,wmax*1.05))\n",
    "    ax.set_ylim((wmin-0.05,wmax*1.05))\n",
    "    # now the background\n",
    "    x = np.arange(wmin,wmax*1.01,0.1)\n",
    "    y = np.copy(x)\n",
    "    nw = len(x)\n",
    "\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "\n",
    "    XY = np.stack([X,Y],axis=2)\n",
    "    VXY = np.empty_like(XY)\n",
    "    gamma = gammahat*Tcycle\n",
    "    weights_direction = lambda w : train_weights_vector_field_direction(\n",
    "                          var_r1,var_r2,correlation,\n",
    "                          w,gamma,\n",
    "                          wmin = wmin, wmax = wmax,\n",
    "                          do_subtractive = do_subtractive)\n",
    "\n",
    "\n",
    "    for ix in range(nw):\n",
    "        for iy in range(nw):\n",
    "            VXY[ix,iy,:] = weights_direction(XY[ix,iy,:])\n",
    "    Vx = VXY[:,:,0]\n",
    "    Vy = VXY[:,:,1]\n",
    "    ax.quiver(X,Y,Vx,Vy, linewidth=None, color=\"black\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698b9ffcff0c4cdf9670b827bbc3616c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='mean_r1', max=5.0), FloatSlider(value=3.0, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "interact_manual(train_weights_bounded_plot,mean_r1=(0.0,5.0,0.1),mean_r2=(0.0,5.0,0.1),\n",
    "        var_r1=(0.01,2.0,0.01), var_r2=(0.01,2.0,0.01),correlation=(-0.99,0.99,0.01),\n",
    "        w1_start = (0.01,1.0,0.01) ,w2_start = (0.01,1.0,0.01)   );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is zero\n"
     ]
    }
   ],
   "source": [
    "if 0.0 == 0:\n",
    "    print(\"is zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "5e3b54db-e48f-43a7-b40f-09467f2d2c99",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/comp-neural-circuits/plasticity-workshop/blob/dev/rate_based.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "70cb080a-e9a3-4007-b9cb-f7ab20b92c2c",
    "deepnote_cell_type": "text-cell-h1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Rate-based Plasticity Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6f485884-d360-4f23-9481-8c834974a155",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Hebbian Plasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9faf8d82-d8b7-41e5-a255-290fb1557024",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Goals**\n",
    "+ Covariance-based learning rule is equivalent to detecting the first principal component of the activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c9f07e91-b33e-49da-9b42-eb3a744cded3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4a92bc37-cb67-4f91-aea7-3682fdd62113",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8501,
    "execution_start": 1644223398431,
    "is_code_hidden": true,
    "is_output_hidden": true,
    "source_hash": "7c291202",
    "tags": [
     "hide_output",
     "remove_output",
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib ipywidgets scikit-learn --quiet\n",
    "import numpy as np\n",
    "import scipy.linalg as lin\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "#plt.style.use(\"https://github.com/comp-neural-circuits/plasticity-workshop/raw/dev/plots_style.txt\")\n",
    "plt.style.use(\"plots_style.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e047227c-e297-436b-aa18-f26e2976f0df",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "94b14042-aade-4b82-8b77-2f6e3d9b3b8e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1644222477799,
    "source_hash": "4199937f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ornstein_uhlenbeck(mean,cov,dt,Ttot,dts=1E-2):\n",
    "  \"\"\"\n",
    "  Generates a multi-dimensional Ornstein-Uhlenbeck process.\n",
    "\n",
    "  Parameters :\n",
    "  mean (numpy vector) : desired mean\n",
    "  cov  (matrix)   : covariance matrix (symmetric, positive definite)\n",
    "  dt   (real)     : timestep output\n",
    "  Tot  (real)     : total time\n",
    "  dts = 1E-3 (real) : simulation timestep\n",
    "\n",
    "  Returns :\n",
    "  times (numpy vector)\n",
    "  rates (numpy matrix)  :  rates[i,j] is the rate of unit i at time times[j]\n",
    "  \"\"\"\n",
    "  times = np.linspace(0.0,Ttot-dt,num=int(Ttot/dt))\n",
    "  n = len(mean)\n",
    "  nTs = int(Ttot/dts)\n",
    "  rates_all = np.empty((n,nTs))\n",
    "  rates_all[:,0] = mean\n",
    "  L = lin.cholesky(cov)\n",
    "  nskip = int(dt/dts)\n",
    "  assert round(dts*nskip,5) == dt , \"dt must be multiple of  \" + str(dts)\n",
    "  for t in range(1,nTs):\n",
    "    dr = dts*(mean-rates_all[:,t-1])\n",
    "    dpsi = np.sqrt(2*dts)*(L.T @ rng.standard_normal(n))\n",
    "    rates_all[:,t] = rates_all[:,t-1] + dr + dpsi\n",
    "  # subsample \n",
    "  rates = rates_all[:,::nskip]\n",
    "  return times,rates\n",
    "  \n",
    "def twodimensional_UL(mean1,var1,mean2,var2,corr,dt,Ttot,dts=1E-2):\n",
    "  \"\"\"\n",
    "  Generates samples from a 2D Ornstein-Uhlenbeck process.\n",
    "\n",
    "  Parameters :\n",
    "  mean1 (real) : mean on first dimension\n",
    "  var1  (real) : variance on first dimension (at dt=1. intervals)\n",
    "  mean2 (real) : - \n",
    "  var2  (real) : - \n",
    "  corr  (real) : correlation coefficient \n",
    "  dt   (real)     : timestep output\n",
    "  Tot  (real)     : total time\n",
    "  dts = 1E-3 (real) : simulation timestep\n",
    "\n",
    "  Returns :\n",
    "  times  (numpy vector)\n",
    "  rates1 (numpy vector)\n",
    "  rates2 (numpy vector)\n",
    "  \"\"\"\n",
    "  assert -1<=corr<=1, \"correlation must be in (-1,1) interval\"\n",
    "  var12 = corr*np.sqrt(var1*var2)\n",
    "  (times, rates) = ornstein_uhlenbeck(\n",
    "      np.array([mean1,mean2]),\n",
    "      np.array([[var1,var12],[var12,var2]]),\n",
    "      dt,Ttot,dts)\n",
    "  return times, rates[0,:],rates[1,:]\n",
    "\n",
    "\n",
    "def plot_r1_and_r2(correlation=0.0,mean_r1=0.0,mean_r2=0.0,var_r1=1.0,var_r2=1.0):\n",
    "    times,rates1,rates2 = twodimensional_UL(mean_r1,var_r1,mean_r2,var_r2,correlation,0.1,60.0)\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8,10)) #gridspec_kw={'height_ratios': [3, 1]})\n",
    "    ax1.plot(times,rates1)\n",
    "    ax1.plot(times,rates2)\n",
    "    ax1.set_xlabel(\"time (s)\")\n",
    "    ax1.set_ylabel(\"rate (Hz)\")\n",
    "    ax1.set_title(\"time traces\")\n",
    "    ax2.scatter(rates1,rates2,color=\"black\")\n",
    "    ax2.set_title(\"samples r1 Vs r2\")\n",
    "    ax2.set_xlabel(\"rate 1 (Hz)\")\n",
    "    ax2.set_ylabel(\"rate 2 (Hz)\")\n",
    "    ax2.axis(\"equal\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize noisy rate inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we generate a noisy rate trace from $N$ neurons. $r_j(t)$ indicates the rate of neuron $j=1,2,\\ldots\\,N$ at time $t$. Neurons are, in general, correlated with each other.\n",
    "\n",
    "In the figure below, you can see the traces of 2 neurons, simulated for 60 seconds. You don't need to read or understand this code. Try to modify some of the parameters to understand their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_r1_and_r2,mean_r1=(0.0,5.0,0.1),mean_r2=(0.0,5.0,0.1),\n",
    "        var_r1=(0.01,2.0,0.01), var_r2=(0.01,2.0,0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute response of output neuron based on input activity and weights  (exercise 1 ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r_\\text{out}(t) = \\sum_{j=1}^N w_j r_j(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_response(r_input,weights):\n",
    "    \"\"\"\n",
    "    Computes the response of a neuron that receives a series of inputs over time.  \n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) :  r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights (vector) :  weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    \n",
    "    Returns :\n",
    "    r_output (vector) : r_output[t] is the rate of the output neuron at timestep t\n",
    "    \"\"\"\n",
    "    \n",
    "    # I think this can be done with np.dot , but I don't like to see it applied to matrices\n",
    "    # so I propose a more canonical broadcasting\n",
    "    \n",
    "    r_input_weighted = r_input * weights[:,np.newaxis] # multiply columnwise\n",
    "    r_output = r_input_weighted.sum(axis=0) # and sum columnwise\n",
    "    return r_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weight update for correlation based and covariance based rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the reponse of the output neuron  $r_\\text{out}(t)$ , you can calculate the update in synaptic weights due to rate-based plasticiy.\n",
    "\n",
    "\n",
    "For the correlation-based rule, we have :\n",
    "$$ \n",
    "\\Delta w_j = \\gamma \\; \\left<  r_\\text{out}(t) \\; r_j(t)  \\right>_t\n",
    "$$\n",
    "\n",
    "\n",
    "For the covariance based rule, we are using a covariance, instead :\n",
    "$$ \n",
    "\\Delta w_j = \\gamma \\; \\left<  \\left(r_\\text{out}(t) - \\bar{r}_\\text{out}\\right)\n",
    "\\; \\left(r_j(t) - \\bar{r}_j \\right)  \\right>_t \\quad \\text{with} \\quad \n",
    "\\bar{r}_\\text{out} = \\left< r_\\text{out}(t) \\right>_t \\quad \\text{and} \\quad\n",
    "\\bar{r}_j = \\left< r_j(t) \\right>_t \n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_updates_correlation(r_input,weights_current,gamma):\n",
    "    \"\"\"\n",
    "    Computes the weight updates according to the correlation rule\n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) :  r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights_current (vector) :  weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    \n",
    "    Returns :\n",
    "    weight_updates (vector) : the update on each weight after this training interval\n",
    "    \"\"\"\n",
    "\n",
    "    # TIPS : \n",
    "    # use the rate_response function that you defined before !\n",
    "   \n",
    "    r_output = rate_response(r_input,weights_current)\n",
    "    r_product  = r_output * r_input  # broadcast by row\n",
    "    weight_updates = gamma * r_product.mean(axis=1) # mean over time dimension\n",
    "    return weights_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_updates_covariance(r_input,weights_current,gamma):\n",
    "    \"\"\"\n",
    "    Computes the weight updates according to the covariance rule\n",
    "    \n",
    "    Parameters :\n",
    "    r_input (matrix) :  r_input[i,t] is the rate of input neuron i at timestep t\n",
    "    weights_current (vector) :  weights[i] is the synaptic strenght between neuron i and the output neuron\n",
    "    \n",
    "    Returns :\n",
    "    weight_updates (vector) : the update on each weight after this training interval\n",
    "    \"\"\"\n",
    "    \n",
    "    # TIPS : \n",
    "    # it is very similar to the correlation rule, except you need to subtract the mean rates!\n",
    "    # r_input_means = r_input.mean(axis=1)  # (mean over time axis)\n",
    "    r_output_mean = r_output.mean() # mean of a vector -> scalar value\n",
    "    r_output = rate_response(r_input,weights_current)\n",
    "    r_output_meanzero = r_output - r_output_mean\n",
    "    r_input_means = r_input.mean(axis=1) # mean over time axis\n",
    "    r_input_meanzero = r_input - r_input_means[:,np.newaxis] # broadcast on columns\n",
    "    \n",
    "    # now same as before\n",
    "    r_product = r_output_meanzero * r_input_meanzero\n",
    "    weight_updates = gamma * r_product.mean(axis=1) # mean over time dimension\n",
    "    return weights_update\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "5e3b54db-e48f-43a7-b40f-09467f2d2c99",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
